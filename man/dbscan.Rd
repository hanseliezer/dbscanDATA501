% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dbscan.R
\name{dbscan}
\alias{dbscan}
\alias{is_core_point}
\title{Density-based spatial clustering of applications with noise (DBSCAN)}
\usage{
dbscan(
  data,
  eps,
  min_pts,
  metric = "euclidean",
  normalise = TRUE,
  border_pts = TRUE
)

is_core_point(data, eps, min_pts, metric = "euclidean", normalise = TRUE)
}
\arguments{
\item{data}{Dataset or distance matrix to be clustered.}

\item{eps}{Maximum distance in which to find \code{min_pts} neighbours to form a cluster.}

\item{min_pts}{Minimum number of points required to be found within \code{eps} distance to form a cluster.}

\item{metric}{Distance metric. Defaults to \code{euclidean}, other options are \code{manhattan} and
\code{precomputed}. If \code{precomputed}, \code{data} must be a distance matrix.}

\item{normalise}{Logical; whether to normalise \code{data} before fitting. Defaults to \code{TRUE}.}

\item{border_pts}{Logical; whether "border points" should be included in a cluster.
Defaults to \code{TRUE}.}
}
\value{
\code{dbscan()} returns a list object of class \code{dbscan} with the following components:

\item{dataset }{ Original dataset being clustered.}
\item{eps }{ Value of \code{eps} parameter used.}
\item{min_pts }{ Value of \code{min_pts} parameter used.}
\item{metric }{ Distance metric used.}
\item{border_pts }{ Whether border points are clustered.}
\item{cluster_labs }{ Integer vector with indicating cluster membership. Noise points are assigned 0.}
\item{fitting_time }{ Total algorithm fitting time in seconds.}

\code{is_core_point()} returns a logical vector indicating whether each observation in the dataset would be
considered a core point under the given \code{eps} and \code{min_pts} parameters.
}
\description{
Applies the DBSCAN algorithm to a given dataset.
}
\details{
The most important parameters to set are \code{min_pts} and \code{eps}

If dataset is not yet normalised, it is highly recommended to set \code{normalise} to true: as a distance-based
algorithm, DBSCAN is still sensitive to features being on varying scales

\code{border_pts = TRUE} would be equivalent to the original DBSCAN algorithm described by Ester et al.,
while \code{FALSE} would be equivalent to DBSCAN* described in Campello et al. 2013
}
\examples{
\dontrun{
blobs <- read.csv('blobs.csv')
dbscan(blobs, 5, 0.2)
}
}
\keyword{clustering}
